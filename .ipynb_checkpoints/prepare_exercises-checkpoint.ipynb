{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677d7583",
   "metadata": {},
   "source": [
    "# NLP Prepare Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d0be2",
   "metadata": {},
   "source": [
    "1. Define a function named ```basic_clean```. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "\n",
    "2. Define a function named ```tokenize```. It should take in a string and tokenize all the words in the string.\n",
    "\n",
    "3. Define a function named ```stem```. It should accept some text and return the text after applying stemming to all the words.\n",
    "\n",
    "4. Define a function named ```lemmatize```. It should accept some text and return the text after applying lemmatization to each word.\n",
    "\n",
    "5. Define a function named ```remove_stopwords```. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "- This function should define two optional parameters, ```extra_words``` and ```exclude_words```. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n",
    "\n",
    "6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe ```news_df```.\n",
    "\n",
    "7. Make another dataframe for the Codeup blog posts. Name the dataframe ```codeup_df```.\n",
    "\n",
    "8. For each dataframe, produce the following columns:\n",
    "\n",
    "- ```title``` to hold the title\n",
    "- ```original``` to hold the original article/post content\n",
    "- ```clean``` to hold the normalized and tokenized original with the stopwords removed.\n",
    "- ```stemmed``` to hold the stemmed version of the cleaned data.\n",
    "- ```lemmatized``` to hold the lemmatized version of the cleaned data.\n",
    "\n",
    "9. Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030804df",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f374e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/natasharivers/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/natasharivers/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/natasharivers/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#unicode, regex, json for text digestion\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "#natural language toolkit -> tokenization, stopwords\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "#standard ds imports\n",
    "import pandas as pd\n",
    "from time import strftime\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#custom import\n",
    "import acquire\n",
    "\n",
    "#ignore warnings import\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21e760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the categories desired\n",
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\"]\n",
    "\n",
    "#use function from acquire.py\n",
    "news_df = acquire.get_news_articles_data(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31c4096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women to get free entry to matches in inaugura...</td>\n",
       "      <td>Women and girls will be getting free entry to ...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let's win polls first: Farooq to Kharge on Opp...</td>\n",
       "      <td>National Conference patron Farooq Abdullah on ...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harassed for independent thinking: INC on CPR'...</td>\n",
       "      <td>Senior Congress leader Jairam Ramesh said Cent...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024 polls are about who should be defeated: T...</td>\n",
       "      <td>Tamil Nadu CM MK Stalin, speaking at his birth...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK's legal process independent of govt: UK min...</td>\n",
       "      <td>British Foreign Secretary James Cleverly on We...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Women to get free entry to matches in inaugura...   \n",
       "1  Let's win polls first: Farooq to Kharge on Opp...   \n",
       "2  Harassed for independent thinking: INC on CPR'...   \n",
       "3  2024 polls are about who should be defeated: T...   \n",
       "4  UK's legal process independent of govt: UK min...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Women and girls will be getting free entry to ...  national  \n",
       "1  National Conference patron Farooq Abdullah on ...  national  \n",
       "2  Senior Congress leader Jairam Ramesh said Cent...  national  \n",
       "3  Tamil Nadu CM MK Stalin, speaking at his birth...  national  \n",
       "4  British Foreign Secretary James Cleverly on We...  national  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006a52ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Women and girls will be getting free entry to matches in the inaugural season of Women's Premier League (WPL), which will begin on March 4. Meanwhile, for men and boys tickets are being sold at a price of ₹100 and ₹400. The tournament will be held in Mumbai's Brabourne Stadium and Navi Mumbai's Dr DY Patil Sports Academy.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use first article [0] to use as test string\n",
    "test_string = news_df.content[0]\n",
    "test_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4a115",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5627a0b",
   "metadata": {},
   "source": [
    "### Let's get into the exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95953699",
   "metadata": {},
   "source": [
    "<b>1. Define a function named ```basic_clean```</b>\n",
    "It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d79df",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remember:</b> \n",
    "<br>\n",
    "\n",
    "- unicodedata.normalize('NFKD', string): This function normalizes the string by decomposing any composed characters into their basic components using the Unicode Normalization Form Compatibility Decomposition (NFKD) algorithm. This is useful for dealing with certain types of characters that might cause issues when processing text data.\n",
    "\n",
    "- .encode('ascii', 'ignore'): This function encodes the normalized string into ASCII format, ignoring any non-ASCII characters in the process. This is useful if you want to remove any non-ASCII characters from the string.\n",
    "\n",
    "- .decode('utf-8', 'ignore'): This function decodes the ASCII-encoded string back into UTF-8 format, ignoring any encoding errors that might occur. This is useful if you want to convert the ASCII-encoded string back into its original Unicode format.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b57a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in the original text.\n",
    "    The text is all lowercased, \n",
    "    the text is encoded in ascii and any characters that are not ascii are ignored.\n",
    "    The text is then decoded in utf-8 and any characters that are not ascii are ignored\n",
    "    Additionally, special characters are all removed.\n",
    "    A clean article is then returned\n",
    "    '''\n",
    "    #lowercase\n",
    "    string = string.lower()\n",
    "    \n",
    "    #normalize\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    \n",
    "    #remove special characters and replaces it with blank\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7285fb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"women and girls will be getting free entry to matches in the inaugural season of women's premier league wpl which will begin on march 4 meanwhile for men and boys tickets are being sold at a price of 100 and 400 the tournament will be held in mumbai's brabourne stadium and navi mumbai's dr dy patil sports academy\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works\n",
    "basic_clean(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d808c1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways:</b>\n",
    "<br>\n",
    "\n",
    "- All words have been lowercased\n",
    "- All periods, commas and quotations within the text have been removed and replaced with a blank space\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e1f59",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f64bc",
   "metadata": {},
   "source": [
    "<b>2. Define a function named ```tokenize```</b>\n",
    "It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a2675",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remember:</b> \n",
    "<br>\n",
    "\n",
    "- <b>Tokenization</b>: Breaks a text document into individual words or terms, also called tokens. This can be done by splitting the text at whitespace, punctuation marks, or any other separator.\n",
    "<br>\n",
    "\n",
    "<b>Note:</b> There are several ways to tokenize: word tokenization (at white space), sentence tokenization (at period) and character tokenization (at each character)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1601f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string\n",
    "    and returns the string as individual tokens put back into the string\n",
    "    '''\n",
    "    #create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "    #use the tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f40b13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Women and girls will be getting free entry to matches in the inaugural season of Women ' s Premier League ( WPL ) , which will begin on March 4. Meanwhile , for men and boys tickets are being sold at a price of ₹ 100 and ₹ 400. The tournament will be held in Mumbai ' s Brabourne Stadium and Navi Mumbai ' s Dr DY Patil Sports Academy .\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works, only root words (no past tense)\n",
    "tokenize(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64849fd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways:</b>\n",
    "<br>\n",
    "\n",
    "- This function returns the same string, but as individual tokens.\n",
    "- backslashes are considered it's own word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ce3c1",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae1978",
   "metadata": {},
   "source": [
    "<b>3. Define a function named ```stem```<b>\n",
    "It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe15265b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remember:</b> \n",
    "<br>\n",
    "\n",
    "<b>stemming</b>: removes suffixes, pluralities, etc. Returns word to its <u>stem</u>.\n",
    "- Because of this: the word returned may not be an actual word...\n",
    "    - (ex): house --> returns hous\n",
    "    - (ex): calls, called, calling --> are all returned to <u>call</u>.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d26fd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in text\n",
    "    and returns the stem word joined back into the text\n",
    "    '''\n",
    "    #create porter stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    #use the stem, split string using each word\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    #join stem word to string\n",
    "    string = ' '.join(stems)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dace5c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"women and girl will be get free entri to match in the inaugur season of women' premier leagu (wpl), which will begin on march 4. meanwhile, for men and boy ticket are be sold at a price of ₹100 and ₹400. the tournament will be held in mumbai' brabourn stadium and navi mumbai' dr dy patil sport academy.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works, only root words (no past tense)\n",
    "stem(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a4c81",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways:</b>\n",
    "<br>\n",
    "\n",
    "- Now all words are returned to their <u>stem</u> word.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a765772",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb74564",
   "metadata": {},
   "source": [
    "<b>4. Define a function named ```lemmatize```</b> \n",
    "It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15676b1a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remember:</b> \n",
    "<br>\n",
    "\n",
    "- <b>lemmatization</b>: very similar to stemming, <u>but</u> the word must be an actual word present in the dictionary. It returns the word to its <u>root</u> as opposed to its <u>stem</u> like in stemming.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2366e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in a string\n",
    "    and returns the lemmatized word joined back into the string\n",
    "    '''\n",
    "    #create the lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    #look at the article \n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    #join lemmatized words into article\n",
    "    string = ' '.join(lemmas)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f2814b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Women and girl will be getting free entry to match in the inaugural season of Women's Premier League (WPL), which will begin on March 4. Meanwhile, for men and boy ticket are being sold at a price of ₹100 and ₹400. The tournament will be held in Mumbai's Brabourne Stadium and Navi Mumbai's Dr DY Patil Sports Academy.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works\n",
    "lemmatize(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cef2fb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Women',\n",
       " 'and',\n",
       " 'girl',\n",
       " 'will',\n",
       " 'be',\n",
       " 'getting',\n",
       " 'free',\n",
       " 'entry',\n",
       " 'to',\n",
       " 'match',\n",
       " 'in',\n",
       " 'the',\n",
       " 'inaugural',\n",
       " 'season',\n",
       " 'of',\n",
       " \"Women's\",\n",
       " 'Premier',\n",
       " 'League',\n",
       " '(WPL),',\n",
       " 'which',\n",
       " 'will',\n",
       " 'begin',\n",
       " 'on',\n",
       " 'March',\n",
       " '4.',\n",
       " 'Meanwhile,',\n",
       " 'for',\n",
       " 'men',\n",
       " 'and',\n",
       " 'boy',\n",
       " 'ticket',\n",
       " 'are',\n",
       " 'being',\n",
       " 'sold',\n",
       " 'at',\n",
       " 'a',\n",
       " 'price',\n",
       " 'of',\n",
       " '₹100',\n",
       " 'and',\n",
       " '₹400.',\n",
       " 'The',\n",
       " 'tournament',\n",
       " 'will',\n",
       " 'be',\n",
       " 'held',\n",
       " 'in',\n",
       " \"Mumbai's\",\n",
       " 'Brabourne',\n",
       " 'Stadium',\n",
       " 'and',\n",
       " 'Navi',\n",
       " \"Mumbai's\",\n",
       " 'Dr',\n",
       " 'DY',\n",
       " 'Patil',\n",
       " 'Sports',\n",
       " 'Academy.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in test_string.split()]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5c354",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways:</b>\n",
    "<br>\n",
    "\n",
    "- The root word is now returned into the string.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f70a60e",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad604af",
   "metadata": {},
   "source": [
    "<b>5. Define a function named ```remove_stopwords```</b>\n",
    "- It should accept some text and return the text after removing all the stopwords.\n",
    "- This function should define two optional parameters, ```extra_words``` and ```exclude_words```. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473334b3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remember:</b> \n",
    "<br>\n",
    "\n",
    "- <b>stopwords</b>: refers to words that have little significance. They are typically articles, conjunctions and prepositions.\n",
    "    - articles: a, an, the, etc\n",
    "    - conjunctions: for, and, nor, but, yet, etc\n",
    "    - prepositions: in, at, on, by, with, etc\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a87681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in text, extra words and exclude words\n",
    "    and returns a list of text with stopword removed\n",
    "    '''\n",
    "    #create stopword list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    #remove excluded words from list\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    #add the extra words to the list\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    #split the string into different words\n",
    "    words = string.split()\n",
    "    \n",
    "    #create a list of words that are not in the list\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    #join the words that are not stopwords (filtered words) back into the string\n",
    "    string = ' '.join(filtered_words)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d852fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Women girls getting free entry matches inaugural season Women's Premier League (WPL), begin March 4. Meanwhile, men boys tickets sold price ₹100 ₹400. The tournament held Mumbai's Brabourne Stadium Navi Mumbai's Dr DY Patil Sports Academy.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b6ab01",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways:</b>\n",
    "<br>\n",
    "\n",
    "- All stop words have been removed from the string.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d71ff2",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd53fd",
   "metadata": {},
   "source": [
    "<b>6. Use your data from the acquire to produce a dataframe of the news articles.</b>\n",
    "Name the dataframe ```news_df```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee199a6b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> \n",
    "<br>\n",
    "\n",
    "We created a function in the acquire phase to acquire news articles\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b48a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the categories desired\n",
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\"]\n",
    "\n",
    "#use function from acquire.py\n",
    "news_df = acquire.get_news_articles_data(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9aa1532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women to get free entry to matches in inaugura...</td>\n",
       "      <td>Women and girls will be getting free entry to ...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let's win polls first: Farooq to Kharge on Opp...</td>\n",
       "      <td>National Conference patron Farooq Abdullah on ...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harassed for independent thinking: INC on CPR'...</td>\n",
       "      <td>Senior Congress leader Jairam Ramesh said Cent...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024 polls are about who should be defeated: T...</td>\n",
       "      <td>Tamil Nadu CM MK Stalin, speaking at his birth...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK's legal process independent of govt: UK min...</td>\n",
       "      <td>British Foreign Secretary James Cleverly on We...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Women to get free entry to matches in inaugura...   \n",
       "1  Let's win polls first: Farooq to Kharge on Opp...   \n",
       "2  Harassed for independent thinking: INC on CPR'...   \n",
       "3  2024 polls are about who should be defeated: T...   \n",
       "4  UK's legal process independent of govt: UK min...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Women and girls will be getting free entry to ...  national  \n",
       "1  National Conference patron Farooq Abdullah on ...  national  \n",
       "2  Senior Congress leader Jairam Ramesh said Cent...  national  \n",
       "3  Tamil Nadu CM MK Stalin, speaking at his birth...  national  \n",
       "4  British Foreign Secretary James Cleverly on We...  national  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at news_ddf\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d39f8a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      woman girl getting free entry match inaugural ...\n",
       "1      national conference patron farooq abdullah wed...\n",
       "2      senior congress leader jairam ramesh said cent...\n",
       "3      tamil nadu cm mk stalin speaking birthday meet...\n",
       "4      british foreign secretary james cleverly wedne...\n",
       "                             ...                        \n",
       "295    turkish president recep tayyip erdogan ha indi...\n",
       "296    moody ' investor service said expects global g...\n",
       "297    akasa air founder ceo vinay dube announced air...\n",
       "298    indian government ha said ' concerned european...\n",
       "299    sebi barred two individual security market one...\n",
       "Name: content, Length: 300, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply all functions just created to the content column to prep\n",
    "news_df['content'].apply(basic_clean)\\\n",
    ".apply(tokenize)\\\n",
    ".apply(lemmatize)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "715e991e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        woman get free entry match inaugural season wpl\n",
       "1      let ' win poll first farooq kharge opposition ...\n",
       "2      harassed independent thinking inc cpr ' licenc...\n",
       "3                2024 poll defeated tamil nadu cm stalin\n",
       "4      uk ' legal process independent govt uk ministe...\n",
       "                             ...                        \n",
       "295    turkey prez poll likely held may amid quake cr...\n",
       "296      economic growth g20 economy slow 2 2023 moody '\n",
       "297           akasa air hire 300 pilot next 12 month ceo\n",
       "298    india feeling ' little challenged ' eu ' carbo...\n",
       "299    sebi ban 2 1 yr levy 25lakh penalty insider tr...\n",
       "Name: title, Length: 300, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply all functions just created to the title column to prep\n",
    "news_df['title'].apply(basic_clean)\\\n",
    ".apply(tokenize)\\\n",
    ".apply(lemmatize)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae9fe9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways:</b>\n",
    "<br>\n",
    "\n",
    "- We now have a content column and title column that has all the functions we created applied to them.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931ff24",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5d19e",
   "metadata": {},
   "source": [
    "<b>7. Make another dataframe for the Codeup blog posts</b>\n",
    "Name the dataframe ```codeup_df```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ceedd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> \n",
    "<br>\n",
    "\n",
    "We created a function in the acquire phase to acquire codeup blog articles.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18666980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in blogs using acquire.py\n",
    "codeup_df = acquire.get_blog_articles_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce52eac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coding Bootcamp or Self-Learning? Which is Bes...</td>\n",
       "      <td>If you’re interested in embarking on a career ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "1  Black excellence in tech: Panelist Spotlight –...   \n",
       "2  Black excellence in tech: Panelist Spotlight –...   \n",
       "3  Black excellence in tech: Panelist Spotlight –...   \n",
       "4  Coding Bootcamp or Self-Learning? Which is Bes...   \n",
       "\n",
       "                                             content  \n",
       "0  Black excellence in tech: Panelist Spotlight –...  \n",
       "1  Black excellence in tech: Panelist Spotlight –...  \n",
       "2  Black excellence in tech: Panelist Spotlight –...  \n",
       "3  Black excellence in tech: Panelist Spotlight –...  \n",
       "4  If you’re interested in embarking on a career ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at the material\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7853dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    black excellence tech panelist spotlight wilma...\n",
       "1    black excellence tech panelist spotlight steph...\n",
       "2    black excellence tech panelist spotlight james...\n",
       "3    black excellence tech panelist spotlight jeani...\n",
       "4    youre interested embarking career tech likely ...\n",
       "5    codeup pleased announce ranked among 58 best c...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply all functions just created to the content column to prep\n",
    "codeup_df['content'].apply(basic_clean)\\\n",
    ".apply(tokenize)\\\n",
    ".apply(lemmatize)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e4033",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaways:</b>\n",
    "<br>\n",
    "\n",
    "- We now have a title column and content column that has all the functions we created applied to them.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46589a8",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dedebc",
   "metadata": {},
   "source": [
    "<b>8. For each dataframe, produce the following columns</b>:\n",
    "\n",
    "- ```title``` to hold the title\n",
    "- ```original``` to hold the original article/post content\n",
    "- ```clean``` to hold the normalized and tokenized original with the stopwords removed.\n",
    "- ```stemmed``` to hold the stemmed version of the cleaned data.\n",
    "- ```lemmatized``` to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce3813ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ PREP ARTICLES ################################\n",
    "\n",
    "#take dataframe, specify the column, extra and exclude words\n",
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    #original text from content column\n",
    "    df['original'] = df['content']\n",
    "    \n",
    "    #chain together clean, tokenize, remove stopwords\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    #chain clean, tokenize, stem, remove stopwords\n",
    "    df['stemmed'] = df['clean'].apply(stem)\n",
    "    \n",
    "    #clean clean, tokenize, lemmatize, remove stopwords\n",
    "    df['lemmatized'] = df['clean'].apply(lemmatize)\n",
    "    \n",
    "    return df[['title', 'original', 'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70c1ce7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women to get free entry to matches in inaugura...</td>\n",
       "      <td>Women and girls will be getting free entry to ...</td>\n",
       "      <td>women girls getting free entry matches inaugur...</td>\n",
       "      <td>women girl get free entri match inaugur season...</td>\n",
       "      <td>woman girl getting free entry match inaugural ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let's win polls first: Farooq to Kharge on Opp...</td>\n",
       "      <td>National Conference patron Farooq Abdullah on ...</td>\n",
       "      <td>national conference patron farooq abdullah wed...</td>\n",
       "      <td>nation confer patron farooq abdullah wednesday...</td>\n",
       "      <td>national conference patron farooq abdullah wed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harassed for independent thinking: INC on CPR'...</td>\n",
       "      <td>Senior Congress leader Jairam Ramesh said Cent...</td>\n",
       "      <td>senior congress leader jairam ramesh said cent...</td>\n",
       "      <td>senior congress leader jairam ramesh said cent...</td>\n",
       "      <td>senior congress leader jairam ramesh said cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024 polls are about who should be defeated: T...</td>\n",
       "      <td>Tamil Nadu CM MK Stalin, speaking at his birth...</td>\n",
       "      <td>tamil nadu cm mk stalin speaking birthday meet...</td>\n",
       "      <td>tamil nadu cm mk stalin speak birthday meet we...</td>\n",
       "      <td>tamil nadu cm mk stalin speaking birthday meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK's legal process independent of govt: UK min...</td>\n",
       "      <td>British Foreign Secretary James Cleverly on We...</td>\n",
       "      <td>british foreign secretary james cleverly wedne...</td>\n",
       "      <td>british foreign secretari jame cleverli wednes...</td>\n",
       "      <td>british foreign secretary james cleverly wedne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Women to get free entry to matches in inaugura...   \n",
       "1  Let's win polls first: Farooq to Kharge on Opp...   \n",
       "2  Harassed for independent thinking: INC on CPR'...   \n",
       "3  2024 polls are about who should be defeated: T...   \n",
       "4  UK's legal process independent of govt: UK min...   \n",
       "\n",
       "                                            original  \\\n",
       "0  Women and girls will be getting free entry to ...   \n",
       "1  National Conference patron Farooq Abdullah on ...   \n",
       "2  Senior Congress leader Jairam Ramesh said Cent...   \n",
       "3  Tamil Nadu CM MK Stalin, speaking at his birth...   \n",
       "4  British Foreign Secretary James Cleverly on We...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  women girls getting free entry matches inaugur...   \n",
       "1  national conference patron farooq abdullah wed...   \n",
       "2  senior congress leader jairam ramesh said cent...   \n",
       "3  tamil nadu cm mk stalin speaking birthday meet...   \n",
       "4  british foreign secretary james cleverly wedne...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  women girl get free entri match inaugur season...   \n",
       "1  nation confer patron farooq abdullah wednesday...   \n",
       "2  senior congress leader jairam ramesh said cent...   \n",
       "3  tamil nadu cm mk stalin speak birthday meet we...   \n",
       "4  british foreign secretari jame cleverli wednes...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  woman girl getting free entry match inaugural ...  \n",
       "1  national conference patron farooq abdullah wed...  \n",
       "2  senior congress leader jairam ramesh said cent...  \n",
       "3  tamil nadu cm mk stalin speaking birthday meet...  \n",
       "4  british foreign secretary james cleverly wedne...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign variable to our new prepped dataframe\n",
    "prep_news = prep_article_data(news_df, 'content', extra_words =[], exclude_words=[])\n",
    "\n",
    "#take a look\n",
    "prep_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef946699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title         Let's win polls first: Farooq to Kharge on Opp...\n",
       "original      National Conference patron Farooq Abdullah on ...\n",
       "clean         national conference patron farooq abdullah wed...\n",
       "stemmed       nation confer patron farooq abdullah wednesday...\n",
       "lemmatized    national conference patron farooq abdullah wed...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at one article\n",
    "prep_news.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a37ca41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>black excellence tech panelist spotlight wilma...</td>\n",
       "      <td>black excel tech panelist spotlight wilmari de...</td>\n",
       "      <td>black excellence tech panelist spotlight wilma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>black excellence tech panelist spotlight steph...</td>\n",
       "      <td>black excel tech panelist spotlight stephani j...</td>\n",
       "      <td>black excellence tech panelist spotlight steph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>black excellence tech panelist spotlight james...</td>\n",
       "      <td>black excel tech panelist spotlight jame coope...</td>\n",
       "      <td>black excellence tech panelist spotlight james...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>black excellence tech panelist spotlight jeani...</td>\n",
       "      <td>black excel tech panelist spotlight jeanic fre...</td>\n",
       "      <td>black excellence tech panelist spotlight jeani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coding Bootcamp or Self-Learning? Which is Bes...</td>\n",
       "      <td>If you’re interested in embarking on a career ...</td>\n",
       "      <td>youre interested embarking career tech likely ...</td>\n",
       "      <td>your interest embark career tech like taken lo...</td>\n",
       "      <td>youre interested embarking career tech likely ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "1  Black excellence in tech: Panelist Spotlight –...   \n",
       "2  Black excellence in tech: Panelist Spotlight –...   \n",
       "3  Black excellence in tech: Panelist Spotlight –...   \n",
       "4  Coding Bootcamp or Self-Learning? Which is Bes...   \n",
       "\n",
       "                                            original  \\\n",
       "0  Black excellence in tech: Panelist Spotlight –...   \n",
       "1  Black excellence in tech: Panelist Spotlight –...   \n",
       "2  Black excellence in tech: Panelist Spotlight –...   \n",
       "3  Black excellence in tech: Panelist Spotlight –...   \n",
       "4  If you’re interested in embarking on a career ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  black excellence tech panelist spotlight wilma...   \n",
       "1  black excellence tech panelist spotlight steph...   \n",
       "2  black excellence tech panelist spotlight james...   \n",
       "3  black excellence tech panelist spotlight jeani...   \n",
       "4  youre interested embarking career tech likely ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  black excel tech panelist spotlight wilmari de...   \n",
       "1  black excel tech panelist spotlight stephani j...   \n",
       "2  black excel tech panelist spotlight jame coope...   \n",
       "3  black excel tech panelist spotlight jeanic fre...   \n",
       "4  your interest embark career tech like taken lo...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  black excellence tech panelist spotlight wilma...  \n",
       "1  black excellence tech panelist spotlight steph...  \n",
       "2  black excellence tech panelist spotlight james...  \n",
       "3  black excellence tech panelist spotlight jeani...  \n",
       "4  youre interested embarking career tech likely ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign variable to our new prepped dataframe\n",
    "prep_codeup = prep_article_data(codeup_df, 'content', extra_words =[], exclude_words=[])\n",
    "\n",
    "#take a look\n",
    "prep_codeup.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08f25d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title         Coding Bootcamp or Self-Learning? Which is Bes...\n",
       "original      If you’re interested in embarking on a career ...\n",
       "clean         youre interested embarking career tech likely ...\n",
       "stemmed       your interest embark career tech like taken lo...\n",
       "lemmatized    youre interested embarking career tech likely ...\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at one article\n",
    "prep_codeup.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8637cba2",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1ccc0",
   "metadata": {},
   "source": [
    "<b>9. Ask yourself</b>:\n",
    "\n",
    "- a. If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- b. If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- c. If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe4a937",
   "metadata": {},
   "source": [
    "<b>In general: \n",
    "- lemmatize: for smaller dataset, it is slower\n",
    "- stemming: for larger dataset, it is faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf10454",
   "metadata": {},
   "source": [
    "<b>Answers</b>: \n",
    "- a. lemmatize your text. The corpus is fairly small.\n",
    "- b. stem your text. The dataset is larger and stemming is faster.\n",
    "- c. If you are getting charged you'd probably want to stem because it is faster-- you'd get charged less."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
